{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# About\n",
    "Here are presented different approaches of reconstruction (estimation)\n",
    "of dynamical and diffusional parameters of Ito's processes in regard of\n",
    "randomness of their nature. Last one meaning that we don't imply any functional\n",
    "representation of them.\n",
    "\n",
    "### Brief overview\n",
    "\n",
    "$S(t) = S_t$ is called an Ito process if it satisfies next equality:\n",
    "$$ \n",
    "dS_t = a(t, S_t) \\cdot dt + b(t, S_t) \\cdot dW \n",
    "$$ (Ito_proc)\n",
    "\n",
    "\n",
    "We can create estimation of:\n",
    "1. Distribution of parameters\n",
    "2. Point-to-point\n",
    "\n",
    "\n",
    "### 1. Estimation of coefficients distribution\n",
    "\n",
    "Let $S(t_i) = S_i, \\quad a(t_i, S_i) = a_i, \\quad b(t_i, S_i) = b_i$. Then\n",
    "$$\n",
    "\\Delta S = S_i - S_{i-1} \\approx a(t_i, S_i) \\Delta t + b(t_i, S_i) \\Delta W \n",
    "$$ (my_label)\n",
    "\n",
    "$$\n",
    "\\Rightarrow\n",
    "\\mathbb{P}(\\Delta S < x) \\approx \\mathbb{P}(\\Delta W < \\frac{x - a_i \\Delta t}{b_i}),\n",
    "\\quad \\text{where } \\Delta W \\sim \\mathcal{N}(0,\\Delta t)\\,\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finito.simulator import generateGeneralWiener\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate process\n",
    "dummyX = generateGeneralWiener(\n",
    "    a=3, b=0.4, dt=np.timedelta64(1, \"ms\"), T=np.timedelta64(10, \"s\")\n",
    ")\n",
    "# Take differences\n",
    "dX = np.diff(dummyX)\n",
    "\n",
    "# Take a look on result\n",
    "f, ax = plt.subplots(3, 1, figsize=(10, 10))\n",
    "ax[0].plot(dummyX)\n",
    "ax[0].set_title(\"Original process\")\n",
    "ax[1].plot(dX)\n",
    "ax[1].set_title(\"Differences\")\n",
    "sns.histplot(dX, kde=True, ax=ax[2])\n",
    "ax[2].set_title(\"Distribution of differences\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "gmm = GaussianMixture(\n",
    "    n_components=1,\n",
    ")\n",
    "\n",
    "gmm.fit(dX.reshape(-1, 1))\n",
    "\n",
    "print(\n",
    "    \"Model parameters after fitting:\",\n",
    "    f\"Means: {gmm.means_[0]}\",\n",
    "    f\"Covariances: {gmm.covariances_.flatten()}\",\n",
    "    sep=\"\\n\",\n",
    ")\n",
    "__time_delta = np.timedelta64(1, \"s\") / np.timedelta64(1, \"ms\")\n",
    "print(\n",
    "    \"As we can see it differs from initial a and b parameters on time delta:\",\n",
    "    __time_delta,\n",
    ")\n",
    "print(\n",
    "    f\"Means: {gmm.means_ * __time_delta}\",\n",
    "    f\"Covariances: {gmm.covariances_ * __time_delta}\",\n",
    "    f\"Standard deviation: {np.sqrt(gmm.covariances_ * __time_delta)}\",\n",
    "    sep=\"\\n\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
